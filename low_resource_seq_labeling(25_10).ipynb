{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8YGzEWTS66qUcw5pStlAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naghamghanim/low_resource_seq_labeling_master/blob/main/low_resource_seq_labeling(25_10).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wpH5uDkp6dtP",
        "outputId": "235f38ac-847d-44a4-e8e0-2e62b883176d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 25 18:29:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Verify that you have the GPU recognized \n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/low_resource_seq_labeling_master\n",
        "!git clone https://github.com/naghamghanim/low_resource_seq_labeling_master.git"
      ],
      "metadata": {
        "id": "wY3dZobk69NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "5PtRMCP27QOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make output directory\n",
        "!mkdir /content/output/"
      ],
      "metadata": {
        "id": "g0KQW8dZ8zSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import argparse\n",
        "sys.path.append('/content/low_resource_seq_labeling_master/')"
      ],
      "metadata": {
        "id": "LTxyAR0s8_eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XLMR models**"
      ],
      "metadata": {
        "id": "JAZ1suaHuMmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mkdir pretrained_models\n",
        "\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/fairseq/models/xlmr.base.tar.gz # base model\n",
        "!tar -xzvf xlmr.base.tar.gz # extract it\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/fairseq/models/xlmr.large.tar.gz # large model\n",
        "!tar -xzvf xlmr.large.tar.gz"
      ],
      "metadata": {
        "id": "OjzpLYGWuuM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Finetuning**"
      ],
      "metadata": {
        "id": "77H11COZvT1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "id": "tFQ7Q7Y4xQSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "JRHRUoJGxe-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairseq"
      ],
      "metadata": {
        "id": "2yT6JZOUhNB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch==1.4 torchvision"
      ],
      "metadata": {
        "id": "bsjcl-ekiVgA",
        "outputId": "8ea1759e-4905-4fa6-cb4b-239f5329f070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[K     |██████████████████████████████▊ | 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.9 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 4.0 MB 38.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 4.0 MB 38.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.4.0 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\n",
            "fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf"
      ],
      "metadata": {
        "id": "nmPdBKEPjbGx",
        "outputId": "2b903293-efd7-47fb-e131-f91a5c41162f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TorchCRF"
      ],
      "metadata": {
        "id": "6qOYZ8_ehiHz",
        "outputId": "4eefef74-2292-4176-fb80-2ab4da25f167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TorchCRF\n",
            "  Downloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from TorchCRF) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from TorchCRF) (1.4.0)\n",
            "Installing collected packages: TorchCRF\n",
            "Successfully installed TorchCRF-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the seqeval\n",
        "!git clone https://github.com/chakki-works/seqeval.git"
      ],
      "metadata": {
        "id": "CeBZ64ZYetfR",
        "outputId": "b264e7d8-0851-4a16-8e60-efb4eec12d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'seqeval'...\n",
            "remote: Enumerating objects: 790, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 790 (delta 4), reused 0 (delta 0), pack-reused 781\u001b[K\n",
            "Receiving objects: 100% (790/790), 172.58 KiB | 8.22 MiB/s, done.\n",
            "Resolving deltas: 100% (454/454), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from main import main"
      ],
      "metadata": {
        "id": "YtBFeIgmwGGI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#python main.py --data_dir=data_path --task_name=ner \\\n",
        " #       --output_dir=output_dir \\\n",
        "  #      --max_seq_length=320 --num_train_epochs 5 \\\n",
        "  #      --do_eval --warmup_proportion=0.1 \\\n",
        "  #      --pretrained_path pretrained_models/xlmr.base/ \\\n",
        "  #      --learning_rate 0.00001\\\n",
        "  #      --gradient_accumulation_steps 1 --eval_on test --dropout 0.1\\\n",
        "  #      --train_batch_size 16 --eval_batch_size 128 --do_train\n",
        "\n",
        "args_dict = {\n",
        "    \"data_dir\": \"data_path\",\n",
        "    \"output_path\": \"/content/output/\",\n",
        "    \"train_path\": \"/content/low_resource_seq_labeling_master/data/NER/Darwish-MSA/train.txt\",\n",
        "    \"test_path\": \"/content/low_resource_seq_labeling_master/data/NER/Darwish-MSA/test.txt\",\n",
        "    \"val_path\": \"/content/low_resource_seq_labeling_master/data/NER/Darwish-MSA/valid.txt\",\n",
        "    \"task_name\": \"NER\",\n",
        "    \"max_seq_length\": 320,\n",
        "    \"num_train_epochs\": 5,\n",
        "    \"do_eval\": \"\",\n",
        "    \"warmup_proportion\": 0.1,\n",
        "    \"pretrained_path\": \"pretrained_models/xlmr.base/\",\n",
        "    \"learning_rate\": 0.00001,\n",
        "    \"gradient_accumulation_steps\":1,\n",
        "    \"eval_on\":\"test\",\n",
        "    \"dropout\":0.1,\n",
        "    \"train_batch_size\":16,\n",
        "    \"eval_batch_size\":128,\n",
        "    \"do_train\":\"\",\n",
        "}\n",
        "args = argparse.Namespace()\n",
        "args.__dict__ = args_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "O4RdZVFjvVte"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "cnMzb13EnYeF",
        "outputId": "49c4407b-994a-490a-cf62-8fbefbb6a90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] --data_dir DATA_DIR --pretrained_path\n",
            "                             PRETRAINED_PATH --task_name TASK_NAME\n",
            "                             --output_dir OUTPUT_DIR [--cache_dir CACHE_DIR]\n",
            "                             [--max_seq_length MAX_SEQ_LENGTH] [--do_train]\n",
            "                             [--do_eval] [--eval_on EVAL_ON] [--do_lower_case]\n",
            "                             [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                             [--eval_batch_size EVAL_BATCH_SIZE]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                             [--warmup_proportion WARMUP_PROPORTION]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--adam_epsilon ADAM_EPSILON]\n",
            "                             [--max_grad_norm MAX_GRAD_NORM] [--no_cuda]\n",
            "                             [--seed SEED]\n",
            "                             [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                             [--fp16] [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "                             [--loss_scale LOSS_SCALE] [--dropout DROPOUT]\n",
            "                             [--freeze_model] [--use_crf] [--no_pbar]\n",
            "                             [--load_model LOAD_MODEL] [--self_training]\n",
            "                             [--unlabeled_data_dir UNLABELED_DATA_DIR]\n",
            "                             [--self_training_confidence SELF_TRAINING_CONFIDENCE]\n",
            "                             [--K K] [--patience PATIENCE]\n",
            "ipykernel_launcher.py: error: the following arguments are required: --data_dir, --pretrained_path, --task_name, --output_dir\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}